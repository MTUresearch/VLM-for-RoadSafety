# VLM-for-RoadSafety
Run-off-road (ROR) crashes are a major contributor to traffic-related injuries and fatalities, especially in rural areas. Roadside features—such as clear zone width, the presence of safety barriers like guardrails, and the absence of fixed rigid objects—play a critical role in influencing the likelihood and severity of these incidents. As such, accurate and efficient inspection of roadside features is essential for proactive safety assessment. Although computer vision models have been developed to address the time and cost constraints of manually inspecting extensive roadway networks, their effectiveness remains limited due to high demands for annotated training data and challenges with generalizability across diverse environments. To address these limitations, this study conducts a comparative evaluation of several vision-language models with semantic understanding capabilities for detecting key roadside features—such as safety barriers and rigid objects—benchmarking their performance against deep learning approaches.
