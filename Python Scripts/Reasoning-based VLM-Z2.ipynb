{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmACK26dyJck"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8nWq9uSyEFj"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import random\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqdY31WfyQeB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '***'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1) Gather all image paths and their true labels\n",
    "all_images = []\n",
    "true_labels = []\n",
    "\n",
    "# Set folder paths relative to the current working directory\n",
    "base_dir = os.getcwd()\n",
    "dir_paths = {\n",
    "    \"YES\": os.path.join(base_dir, \"Close\"),\n",
    "    \"NO\": os.path.join(base_dir, \"Clear\")\n",
    "}\n",
    "\n",
    "for label, folder in dir_paths.items():\n",
    "    for fname in os.listdir(folder):\n",
    "        if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            all_images.append(os.path.join(folder, fname))\n",
    "            true_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sSg3HM_sm0T"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_final_answer(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a final YES/NO from a reasoning+answer text.\n",
    "    Returns \"YES\", \"NO\", or \"NO\" as a default fallback.\n",
    "    \"\"\"\n",
    "    if not isinstance(response, str) or not response.strip():\n",
    "        return \"NO\"\n",
    "\n",
    "    # 0. Normalize whitespace, unify line endings\n",
    "    text = response.replace(\"\\r\\n\", \"\\n\").strip()\n",
    "\n",
    "    # 1. Quick clean-up: correct common typos and strip Markdown emphasis\n",
    "    #    - fix 'asnwer' → 'answer'\n",
    "    #    - remove surrounding * or ** around YES/NO\n",
    "    text = re.sub(r\"(?i)\\basnwer\\b\", \"answer\", text)\n",
    "    text = re.sub(r\"[*_]*(YES|NO)[*_]*\", r\"\\1\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # 2. Scan from bottom to top for explicit final-answer labels\n",
    "    lines = text.split(\"\\n\")\n",
    "    for line in reversed(lines):\n",
    "        # a) Structured: final answer: YES / final-answer – NO / final answer – YES\n",
    "        m = re.search(\n",
    "            r\"\\bfinal[-\\s]*answer\\s*[:\\-–]?\\s*(YES|NO)\\b\",\n",
    "            line,\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        if m:\n",
    "            return m.group(1).upper()\n",
    "\n",
    "        # b) Flexible: answer: YES / answer – NO\n",
    "        m = re.search(\n",
    "            r\"\\banswer\\s*[:\\-–]?\\s*(YES|NO)\\b\",\n",
    "            line,\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        if m:\n",
    "            return m.group(1).upper()\n",
    "\n",
    "        # c) Phrased: the answer is YES / answer would be NO\n",
    "        m = re.search(\n",
    "            r\"\\b(?:the\\s+)?answer\\s+(?:is|would\\s+be|should\\s+be)\\s+(YES|NO)\\b\",\n",
    "            line,\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        if m:\n",
    "            return m.group(1).upper()\n",
    "\n",
    "        # d) Standalone\n",
    "        if line.strip().upper() in {\"YES\", \"NO\"}:\n",
    "            return line.strip().upper()\n",
    "\n",
    "    # 3. Fallback to frequency count\n",
    "    upper = text.upper()\n",
    "    yes_count = len(re.findall(r\"\\bYES\\b\", upper))\n",
    "    no_count  = len(re.findall(r\"\\bNO\\b\", upper))\n",
    "    if yes_count > no_count:\n",
    "        return \"YES\"\n",
    "    # tie or more NOs\n",
    "    return \"NO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9G1aY0Gwsuf3"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "#model: [gpt-40,gpt-40-mini,gpt4-1,gpt4-1mini]\n",
    "def make_request_zero_shot(base64_image):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    { \"type\": \"text\", \"text\": \"Describe any objects very close in shoulder of the road that you see and look like rigid object. Compare these objects to known characteristics of rock, rocky landscape, and rigid objects. After your reasoning, answer strictly YES or NO that you see the object in image.\" },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"low\"\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbjiQJUCs2Mk",
    "outputId": "d0cf572a-dc4c-4237-b723-c192ef0dbc94"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize storage lists\n",
    "results = []\n",
    "pred_labels = []\n",
    "valid_true_labels = []\n",
    "\n",
    "for img_path, true_label in zip(all_images, true_labels):\n",
    "    base64_img = encode_image(img_path)\n",
    "    response = make_request_zero_shot(base64_img)\n",
    "    \n",
    "    print(f\"image: {img_path}\")\n",
    "    print(\" Response:\", response)\n",
    "\n",
    "    pred = extract_final_answer(response)\n",
    "    \n",
    "    image_id = os.path.basename(img_path)\n",
    "\n",
    "    if pred in [\"YES\", \"NO\"]:\n",
    "        pred_labels.append(pred)\n",
    "        valid_true_labels.append(true_label)\n",
    "\n",
    "        results.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"true_label\": true_label,\n",
    "            \"prediction\": pred,\n",
    "            \"reasoning\": response\n",
    "        })\n",
    "    else:\n",
    "        print(f\"⚠️ Skipped image (no YES/NO detected): {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "5jP2qCXStAlY",
    "outputId": "36e19f38-1e1f-4acd-b36b-e0bc2b2679bb"
   },
   "outputs": [],
   "source": [
    "# 7. Confusion matrix (only on valid results)\n",
    "cm = confusion_matrix(valid_true_labels, pred_labels, labels=[\"YES\", \"NO\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"YES\", \"NO\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I55C6tSVgV3E",
    "outputId": "ed061ddd-d4a9-4430-a11a-c929254924fe"
   },
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(valid_true_labels, pred_labels, labels=[\"YES\", \"NO\"])\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
